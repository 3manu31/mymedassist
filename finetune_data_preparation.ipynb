{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86586cf5",
   "metadata": {},
   "source": [
    "# Data Preparation for Medical Study Assistant Finetuning\n",
    "\n",
    "This notebook helps you organize and prepare your lecture transcripts, curriculum, and study guides into a dataset suitable for finetuning a language model as a medical study assistant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9011b2b8",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "Import Python libraries such as os, pandas, and json for file handling and data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39db7a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee42bd61",
   "metadata": {},
   "source": [
    "## 2. Load and Preview Lecture Transcripts\n",
    "Read sample lecture transcript files from the 'lectures/' directory and display their contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f653c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List and preview lecture transcript files\n",
    "lecture_dir = Path('lectures')\n",
    "lecture_files = list(lecture_dir.glob('*.txt'))\n",
    "\n",
    "for file in lecture_files:\n",
    "    print(f\"\\n--- {file.name} ---\\n\")\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        print(f.read()[:1000])  # Preview first 1000 characters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172be20b",
   "metadata": {},
   "source": [
    "## 3. Load Curriculum Descriptions\n",
    "Read curriculum or program description files from the 'curriculum/' directory and display their contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ab7408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List and preview curriculum files\n",
    "curriculum_dir = Path('curriculum')\n",
    "curriculum_files = list(curriculum_dir.glob('*'))\n",
    "\n",
    "for file in curriculum_files:\n",
    "    print(f\"\\n--- {file.name} ---\\n\")\n",
    "    with open(file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        print(f.read()[:1000])  # Preview first 1000 characters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d0f15c",
   "metadata": {},
   "source": [
    "## 4. Load Study Guides\n",
    "Read study guide files from the 'study_guides/' directory and display their contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4377eb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List and preview study guide files\n",
    "study_guide_dir = Path('study_guides')\n",
    "study_guide_files = list(study_guide_dir.glob('*.md'))\n",
    "\n",
    "for file in study_guide_files:\n",
    "    print(f\"\\n--- {file.name} ---\\n\")\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        print(f.read()[:1000])  # Preview first 1000 characters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb61828e",
   "metadata": {},
   "source": [
    "## 5. Prepare Training Dataset\n",
    "Combine and preprocess the loaded data into a structured format suitable for model finetuning, such as Q&A pairs or summarization tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867fd727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Combine lecture, curriculum, and study guide into a dataset entry\n",
    "# (You can customize this logic for your actual data structure)\n",
    "\n",
    "dataset = []\n",
    "\n",
    "if lecture_files and curriculum_files and study_guide_files:\n",
    "    with open(lecture_files[0], 'r', encoding='utf-8') as lf, \\\n",
    "         open(curriculum_files[0], 'r', encoding='utf-8', errors='ignore') as cf, \\\n",
    "         open(study_guide_files[0], 'r', encoding='utf-8') as sf:\n",
    "        lecture_text = lf.read()\n",
    "        curriculum_text = cf.read()\n",
    "        study_guide_text = sf.read()\n",
    "        entry = {\n",
    "            \"input\": f\"Class: {lecture_files[0].stem}\\nCurriculum: {curriculum_text[:500]}...\\nApproach: Clinical\\nLecture Transcript: {lecture_text[:1000]}...\",\n",
    "            \"output\": study_guide_text[:2000]  # Truncate for preview\n",
    "        }\n",
    "        dataset.append(entry)\n",
    "\n",
    "print(\"Sample dataset entry:\\n\", json.dumps(dataset[0], indent=2) if dataset else \"No data found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c01352a",
   "metadata": {},
   "source": [
    "## 6. Export Dataset for Finetuning\n",
    "Export the processed dataset to the 'data/' directory in JSONL format for use in Hugging Face Transformers/TRL finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f13552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataset to JSONL for finetuning\n",
    "output_path = Path('data/finetune_dataset.jsonl')\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    for entry in dataset:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + '\\n')\n",
    "print(f\"Exported {len(dataset)} entries to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
